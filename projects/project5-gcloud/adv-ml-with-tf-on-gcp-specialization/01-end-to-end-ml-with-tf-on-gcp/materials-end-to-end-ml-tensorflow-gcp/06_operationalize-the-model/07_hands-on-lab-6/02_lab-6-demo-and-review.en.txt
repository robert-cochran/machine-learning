So, now we're on the sixth lab and we need to deploy and predict with the model. So, as before, we change our bucket and project to reflect the quick labs bucket and project. So, let me go ahead and do that, and run that. The TensorFlow version, this is going to, know obviously there's new version of TensorFlow coming all the time, so you can go ahead and change it to reflect the current TensorFlow version that you have. If you're wondering what that is, you can create a new code cell and you can say "import tensorflow as tf" and "print" I think it's "tf version". Let's see if that works. So, this works and I now have, when I'm recording it, I have 1.8. So, I've changed this to be now 1.8. I can run that. So, that's my TensorFlow version, and now the question is do you actually have the data or are you continuing from the previous quick lab where you did the training and you have your model or you don't? In my case, I didn't do it; Chris trained the model. So, what I'm going to do is I'm going to basically go ahead and copy the canonical model over. So, I'll go ahead and do this. I'll do bash and copy the canonical model, the thing that we had trained much earlier when we are developing the course and copy it into my bucket here on Quick Labs. So, at this point, the entire thing should be copied over. So, you notice that all of the checkpoints and everything that was there when we trained it, it has now been copied over, and what we could do is that we can now check whether how to deploy it. So, we can make sure that now that we've copied it, does it actually exist? Nope, it doesn't exist. Why doesn't it exist? Let's see. Let's go ahead and do a gsutil ls to see what the actual path needs to be, where it was written gsutil ls. So, there's baby weight and there is a trained model, and under trained model there is an export and its export Servo is the name of it, Servo. So, this was actually written out with something called Servo instead of exporter. So, there it is. So, we can do that. So, now it exists. So, at this point now, this thing is called Servo. Again, this is going to check what your output directory is called and what I'll do is now I'm going to make a model called baby weight. My version is going to be ml_on_gcp, and I'm basically trying to find this timestamp here, that's the model location and then we don't have anything deployed already. So, there's nothing to delete. So, what we'll do first is that we'll go ahead and create the model. So, let's go ahead and create the model. Having created the model, we'll create a model with this appropriate version. So, we haven't created a model. I'll now create the version and this will take a couple of minutes. Once the version has been created, we should be able to go to the GCP console and see that there is an ML model already deployed. So, we can go to the GCP console, go to the ML Engine and we can say, "What are my models?" and there is a baby weight, it's not yet fully deployed yet, but once it's deployed, you will see a version and so on. So, at that point, all the deployment happens. It takes a couple of minutes, and at that point we should be able to send JSON request to the model, and get JSON responses back. While we are waiting we should probably explain where the Servo or export or whatever comes from. It comes from your model code itself. So, this is something that again, it depends on the name that you gave it when you wrote your train and eval loop. So, when we go into the train and eval loop, you could go down here in the train and evaluation loop and when you export, you basically specify the name of a directory. It really depends on when you wrote the code, what you specified the name of the directory was. It could be export or it could be Servo. It could be whatever it is. So, you do want to find what that name was and that's the one that we are copying. So, in this case, that was Servo, that's why we had to change it from exporter, which is what the current solution is, to Servo, which is what it was when we started developing the course. Still waiting. Just check here, still not done. Now, the version creation is complete. We can go into the GCP details and go ahead and look at the baby weight model. You should see a default version, click on it, and you will see the creation time when it was last used et cetera. We can go ahead and try to run the model by going in and running the next cell, which basically has the data in the form that you expected. So, make sure that when you're calling the model, these columns that you're specifying are the exact same columns and have appropriate types as you trained your model to expect the raw data. With that, you go ahead and you run it and you should get your predictions. At this point, you have walked through the ML process end to end. You started in lab number one by exploring the dataset, and now, in lab number six, you deployed the trained machine learning model as a web service.