Let's do our last lab where we'll actually build a front end that will call the predict API specified by ML engine. So, let's build a web app using Flask which will provide a user interface for an end user to interact with our model. In this case, we're going to jump straight to the cloud but you can even test this locally similar to the approach that we've been doing before if you'd like. Then once we've completed this lab, we'll have completed the end-to -end process of training and operationalizing a model on Cloud ML. So, to get started with the lab, go to console.cloud.google.com and open up a new Cloud Shell. Cloud Shell can be opened at the top right. Once we do that, you may need to clone the training data analysts repo, if you haven't already. That can be done using git clone github.com/GoogleCloudPlatform/training-data-analyst. I've already cloned it so I don't need to do that. Once you have this folder, we'll go into the training-data-analyst/courses/machine_learning/deepdive and we'll go into six. I'll make it a little bigger. Here, we have the serving folder and this contains the logic for creating our web app. What we can do is we're going to run deploy.sh and this will actually deploy our web application for us. But before we do that, let's look into deploy.sh first to see what it's doing. So, if I look into deploy.sh, it's doing a couple of things. It's going into the application folder that we have in this directory, it's installing the requirements including Flask that we'll need to deploy our web app, it's going to run gcloud app create, which creates an app engine within your current google Cloud project, and then deploy, which deploys and builds a container image that will actually contain that app that we're building. Then once we do that, we'll be able to access our web app at the URL for our projectname.appspot.com. So, let's go into the application folder, and let's look at what's actually happening there. So, I'm going to do ls-l, so inside the application folder, there's a couple files of interest. Notably, there is the app.yaml file and this contains, essentially, instructions for deploying our app. Key things here are we're going to use Python 2.7 and for different handlers or routes, we're going to say our URL and then what do we actually want to execute. In this case, the main.app is going to contain the actual logic for launching our web app. Then we're also going to reveal environmental variables that we'll be able to access. So, in this case, the model name is going to be babyweight. So, really, the meat of the code is contained in the main.py. So, let's go ahead and look at that. So, if we do main.py, take a look at it, so now, we're in the main.py file. The main.py file has two key uses. The first and main usage is it will serve as the back end that will be hosting our web application, that the end user's going to enact with. The second usage is it'll provide a wrapper that will help us call the predict API in ML engine. So, let's talk about those at a high-level and then we'll drill into the details. So, here, we have the two decorators for app.route. In this case, we have the base URL and the /form URL. These get displayed to the user when they go to these respective routes, in this case, just the base URL and the /form, and these are what ultimately gets served to the user. In addition, we also have an API/predict route. The end user is not explicitly visiting this page. What happens is the client side in HTML file, it's going to make a post request which is what we specify here, to this API/predict URL. What that's gonna do is it's actually going to do a little bit of pre-processing which we can see here. We're going to, for example, convert gender to string and plurality to string. It's also going to do some processing and converting mother_age from a string to a float, for example. Really, what it's gonna do is it's going to call this get_prediction. So, what is this get_prediction? Well, let's look at that. I just search for it within the file and we have our get_prediction. This code should look very similar to what we've seen so far. Here, we're going to build a input_data JSON which will have the features that the end user had provided to us via their form. This is now input data, we're going to hit the route, we're going to hit the model that we created earlier, the project or model name and version name, and these are what we specified above and they're located in environmental variables. So, now that we've done that, then we can actually get a prediction and we're going to return that prediction. So, this gets returned and then we're going to return JSON back to the user, back to them client-side. Great. So, we've reviewed the main.py file. So, now, let's actually deploy our app and get predictions in real time. So, as we talked about earlier, we'll run the deploy.sh. After a minute or so, the deploy script finishes and we've deployed our app using the App Engine. So, we've actually returned the URL that we can visit so I'm going to go ahead and click that. I'll click this to make sure I'm authenticated. If we look at the route that we're located, we're actually at the form URL, this is what we saw in the main.py, so it's returning the formula HTML file. What we're gonna do now is we're going to provide some feature values that we're going to use to send to the API/predict route. The API/predict route is going to do some preprocessing and then call ML engine predict to give us our babyweight. So, this will take a minute or two because it's the first time we're going to call the ML engine predict in a little while. So, we've gotten our prediction back. For this given features that we then put it, this is what the model that we've trained returns. Let's try changing the value, and we're getting a different result back. So, you can see that this is giving new features and giving a new prediction back. So, that's it, we've built a web app using Flask in App Engine. This web app provides a URL that our user can access. This allows the user to provide features or data that, in turn, calls our trained model using ML engine predict, returns back a response, and the user gets to view the predictions in real time. That's it for this lab and this is also the final lab in end-to-end machine learning.